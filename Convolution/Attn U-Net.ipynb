{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention U-Net: Learning Where to Look for the Pancreas**    \n",
    "*Ozan Oktay, et al.*   \n",
    "[[paper](https://arxiv.org/abs/1804.03999)]   \n",
    "MIDL 2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=None) -> None:\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        if not hidden_dim:\n",
    "            hidden_dim = out_dim\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv3d(in_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv3d(hidden_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class AttnUNet_Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AttnUNet_Encoder, self).__init__()\n",
    "\n",
    "        self.hidden_dim = 16\n",
    "\n",
    "        self.conv1 = ConvLayer(1, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv2 = ConvLayer(self.hidden_dim/2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv3 = ConvLayer(self.hidden_dim/2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv4 = ConvLayer(self.hidden_dim/2, self.hidden_dim)\n",
    "\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h1  = self.conv1(x)\n",
    "        p1  = self.pool(h1)\n",
    "\n",
    "        h2  = self.conv2(p1)\n",
    "        p2  = self.pool(h2)\n",
    "\n",
    "        h3  = self.conv3(p2)\n",
    "        p3  = self.pool(h3)\n",
    "\n",
    "        h4  = self.conv4(p3)\n",
    "        \n",
    "        stage_outputs = [h1, h2, h3]\n",
    "\n",
    "        return h4, stage_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsamplingLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, is_deconv=True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if is_deconv:\n",
    "            self.upsampler = nn.ConvTranspose3d(in_dim, out_dim, kernel_size=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class AttnUNet_Decoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AttnUNet_Decoder, self).__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8034245bc4d3529f9d9ffcd1c0ba194efca112f5dbacb6a250b6873c232e499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
