{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention U-Net: Learning Where to Look for the Pancreas**    \n",
    "*Ozan Oktay, et al.*   \n",
    "[[paper](https://arxiv.org/abs/1804.03999)]   \n",
    "MIDL 2018   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=None) -> None:\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        if not hidden_dim:\n",
    "            hidden_dim = out_dim\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv3d(in_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv3d(hidden_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm3d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class AttnUNet_Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AttnUNet_Encoder, self).__init__()\n",
    "\n",
    "        self.hidden_dim = 32\n",
    "\n",
    "        self.conv1 = ConvLayer(1, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv2 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv3 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv4 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h1  = self.conv1(x)\n",
    "        p1  = self.pool(h1)\n",
    "\n",
    "        h2  = self.conv2(p1)\n",
    "        p2  = self.pool(h2)\n",
    "\n",
    "        h3  = self.conv3(p2)\n",
    "        p3  = self.pool(h3)\n",
    "\n",
    "        h4  = self.conv4(p3)\n",
    "        \n",
    "        stage_outputs = [h1, h2, h3]\n",
    "\n",
    "        return h4, stage_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsamplingLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, is_deconv=True) -> None:\n",
    "        super(UpsamplingLayer, self).__init__()\n",
    "\n",
    "        if is_deconv:\n",
    "            self.upsampler = nn.ConvTranspose3d(in_dim, out_dim, kernel_size=2, stride=2, padding=0)\n",
    "        else:\n",
    "            self.upsampler = nn.Upsample(size=out_dim, scale_factor=2, mode='trilinear')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsampler(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, in_dim, coarser_dim, hidden_dim) -> None:\n",
    "        super(AttentionGate, self).__init__()\n",
    "\n",
    "        self.GridGateSignal_generator = nn.Sequential(\n",
    "                nn.Conv3d(coarser_dim, coarser_dim, kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        # input feature x // the gating signal from a coarser scale\n",
    "        # gating dim == in_dim*2\n",
    "        self.w_x = nn.Conv3d(in_dim, hidden_dim, kernel_size=(2,2,2), stride=(2,2,2), padding=0, bias=False)\n",
    "        self.w_g = nn.Conv3d(coarser_dim, hidden_dim, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.psi = nn.Conv3d(hidden_dim, 1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs, coarser):\n",
    "        query = self.GridGateSignal_generator(coarser)\n",
    "\n",
    "        proj_x = self.w_x(inputs)\n",
    "        proj_g = self.w_g(query)\n",
    "\n",
    "        addtive = F.relu(proj_x + proj_g)\n",
    "        attn_coef = self.psi(addtive)\n",
    "\n",
    "        attn_coef = F.upsample(attn_coef, inputs.size()[2:], mode='trilinear')\n",
    "\n",
    "        return attn_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class AttnUNet_Decoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AttnUNet_Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_dim = 32\n",
    "        self.out_dim    = 2\n",
    "\n",
    "        self.conv1 = ConvLayer(1, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv2 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv3 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2\n",
    "        self.conv4 = ConvLayer(self.hidden_dim//2, self.hidden_dim)\n",
    "\n",
    "\n",
    "        self.hidden_dim = 16\n",
    "        self.attn1  = AttentionGate(self.hidden_dim, self.hidden_dim*2, self.hidden_dim)\n",
    "        self.up1    = UpsamplingLayer(self.hidden_dim*2, self.hidden_dim)\n",
    "        self.conv1  = ConvLayer(self.hidden_dim*2, self.out_dim, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2 # 32\n",
    "        self.attn2  = AttentionGate(self.hidden_dim, self.hidden_dim*2, self.hidden_dim)\n",
    "        self.up2    = UpsamplingLayer(self.hidden_dim*2, self.hidden_dim)\n",
    "        self.conv2  = ConvLayer(self.hidden_dim*2, self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.hidden_dim *= 2 # 64\n",
    "        self.attn3  = AttentionGate(self.hidden_dim, self.hidden_dim*2, self.hidden_dim)\n",
    "        self.up3    = UpsamplingLayer(self.hidden_dim*2, self.hidden_dim)\n",
    "        self.conv3  = ConvLayer(self.hidden_dim*2, self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "    \n",
    "    def forward(self, enc_out, stage_outputs):\n",
    "\n",
    "        attn_g3 = self.attn3(stage_outputs[-1], enc_out) * stage_outputs[-1]\n",
    "        h3      = self.up3(enc_out)\n",
    "        h3      = torch.concat([attn_g3, h3], dim=1)\n",
    "        h3      = self.conv3(h3)\n",
    "\n",
    "        attn_g2 = self.attn2(stage_outputs[-2], h3) * stage_outputs[-2]\n",
    "        h2      = self.up2(h3)\n",
    "        h2      = torch.concat([attn_g2, h2], dim=1)\n",
    "        h2      = self.conv2(h2)\n",
    "\n",
    "        attn_g1 = self.attn1(stage_outputs[-3], h2) * stage_outputs[-3]\n",
    "        h1      = self.up1(h2)\n",
    "        h1      = torch.concat([attn_g1, h1], dim=1)\n",
    "        h1      = self.conv1(h1)\n",
    "\n",
    "        return h1        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8034245bc4d3529f9d9ffcd1c0ba194efca112f5dbacb6a250b6873c232e499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
