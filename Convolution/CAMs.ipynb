{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAMs) Learning Deep Features for Discriminative Localization**   \n",
    "*Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba*   \n",
    "[[paper](https://arxiv.org/abs/1512.04150)]    \n",
    "CVPR 2016  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for VGGnet, we removed the layers after conv5-3 (i.e., pool5 to prb) resulting in a mapping resolution of 14 x 14\n",
    "class CAMs_VGG16(nn.Module):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super(CAMs_VGG16, self).__init__()\n",
    "\n",
    "        # to remove the last pooling layer\n",
    "        # alternative --> nn.Sequential(*list(model.features.children())[:-1])\n",
    "        self.backbone = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*[self.backbone.features[i] for i in range(len(self.backbone.features)-1)])\n",
    "\n",
    "        # we added a convolutional layer of size 3x3, stride 1, pad 1 with 1024 units, followed by a GAP layer and a softmax layer.\n",
    "        self.conv    = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.linear  = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # CNN encoder\n",
    "        h = self.backbone(x)\n",
    "        features = self.conv(h) # (B, 1024, w, h)\n",
    "        p = self.avgpool(features)\n",
    "        p = torch.squeeze(p)\n",
    "        out = self.linear(self.softmax(p))\n",
    "\n",
    "        return out, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define train/test data loaders  \n",
    "# Use data augmentation in training set to mitigate overfitting. \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),                                \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([                       \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "train_dataset = CIFAR100('dataset/cifar100', download=True, train=True, transform=train_transform)\n",
    "test_dataset = CIFAR100('dataset/cifar100', download=True, train=False, transform=test_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, optimizer, criterion):\n",
    "    global_step = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Here starts the train loop.\n",
    "        net.train()\n",
    "        for batch_idx, (x, y) in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            #  Send `x` and `y` to either cpu or gpu using `device` variable. \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            logit, _ = net(x)\n",
    "\n",
    "            accuracy = (logit.argmax(1) == y).float().mean()\n",
    "            loss = criterion(logit, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.\n",
    "            test_accuracy = 0.\n",
    "            test_num_data = 0.\n",
    "            for batch_idx, (x, y) in tqdm(enumerate(test_dataloader)):\n",
    "                x = x.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "\n",
    "                logit, _ = net(x)\n",
    "\n",
    "                loss = criterion(logit, y)\n",
    "\n",
    "                accuracy = (logit.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "                test_loss += loss.item()*x.shape[0]\n",
    "                test_accuracy += accuracy.item()*x.shape[0]\n",
    "                test_num_data += x.shape[0]\n",
    "\n",
    "            test_loss /= test_num_data\n",
    "            test_accuracy /= test_num_data\n",
    "\n",
    "            print(f'Test result of epoch {epoch}/{epochs} || loss : {test_loss:.3f} acc : {test_accuracy:.3f} ')\n",
    "\n",
    "        # scheduler.step()\n",
    "    return best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [01:29,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "model = CAMs_VGG16(num_classes=100)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_accuracy = train_net(model, optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2afe5adcac51d02a2e1812bcf61b8667819276e0f44a7370b1e04a47e62fa1fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
