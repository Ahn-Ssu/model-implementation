{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN32(VGG):\n",
    "    def __init__(self):\n",
    "        super(FCN32, self).__init__(make_layers(cfg['vgg16']))\n",
    "\n",
    "        self.numclass = 21\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(512, 4096, kernel_size=7)\n",
    "        self.conv2 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "\n",
    "        self.classifier = nn.Conv2d(4096, self.numclass, kernel_size=1, stride=1, padding=0)\n",
    "        self.upsampler = nn.ConvTranspose2d(self.numclass, self.numclass, kernel_size=64, stride=32, bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def load_pretrained(self, pretrained_model):\n",
    "        \n",
    "        self.features = pretrained_model.features\n",
    "        fc6 = pretrained_model.classifier[0]\n",
    "        fc7 = pretrained_model.classifier[3]\n",
    "\n",
    "        conv1W = nn.parameter.Parameter(fc6.weight.view(4096,512, 7,7))\n",
    "        conv2W = nn.parameter.Parameter(fc7.weight.view(4096,4096,1,1))\n",
    "\n",
    "        # for the pre-trained weights of VGG16\n",
    "        with torch.no_grad():\n",
    "          self.conv1.weight = conv1W\n",
    "          self.conv2.weight = conv2W\n",
    "\n",
    "    def vgg_layer_forward(self, x, indices):\n",
    "        output = x\n",
    "        start_idx, end_idx = indices\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            output = self.features[idx](output)\n",
    "        return output\n",
    "\n",
    "    def vgg_forward(self, x):\n",
    "        out = {}\n",
    "        layer_indices = [0, 5, 10, 17, 24, 31]\n",
    "        for layer_num in range(len(layer_indices)-1):\n",
    "            x = self.vgg_layer_forward(x, layer_indices[layer_num:layer_num+2])\n",
    "            out[f'pool{layer_num+1}'] = x\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Padding for aligning to the input size\n",
    "        padded_x = F.pad(x, [100, 100, 100, 100], \"constant\", 0)\n",
    "        vgg_features = self.vgg_forward(padded_x)\n",
    "        vgg_pool5 = vgg_features['pool5'].detach()\n",
    "        vgg_pool4 = vgg_features['pool4'].detach()\n",
    "        vgg_pool3 = vgg_features['pool3'].detach()\n",
    "\n",
    "        h = self.conv1(vgg_pool5)\n",
    "        h = self.relu(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = self.relu(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        classified = self.classifier(h)\n",
    "        upsampled = self.upsampler(classified)\n",
    "        out = transforms.functional.crop(upsampled, top=31, left=31, height=x.shape[-2], width=x.shape[-1])\n",
    "\n",
    "        return out\n",
    "\n",
    "    # initialize transdeconv layer with bilinear upsampling.\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN8(FCN32):\n",
    "    def __init__(self):\n",
    "        super(FCN8, self).__init__()\n",
    "\n",
    "        self.numclass = 21\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "\n",
    "        # inheried\n",
    "        # self.conv1 = nn.Conv2d(512, 4096, kernel_size=7)\n",
    "        # self.conv2 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "\n",
    "        self.classifier1 = nn.Conv2d(4096, self.numclass, kernel_size=1)\n",
    "        self.classifier2 = nn.Conv2d(512, self.numclass, kernel_size=1)\n",
    "        self.classifier3 = nn.Conv2d(256, self.numclass, kernel_size=1)\n",
    "\n",
    "        # Learnable upsampling layers in FCN model.\n",
    "        self.trans1 = nn.ConvTranspose2d(self.numclass, self.numclass, kernel_size=4, stride=2, bias=False)\n",
    "        self.trans2 = nn.ConvTranspose2d(self.numclass, self.numclass, kernel_size=4, stride=2, bias=False)\n",
    "        self.trans3 = nn.ConvTranspose2d(self.numclass, self.numclass, kernel_size=16, stride=8, bias=False)\n",
    "\n",
    "        # initialize deconv layer with bilinear upsampling.\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Padding for aligning to the input size\n",
    "        padded_x = F.pad(x, [100, 100, 100, 100], \"constant\", 0)\n",
    "        vgg_features = self.vgg_forward(padded_x)\n",
    "        vgg_pool5 = vgg_features['pool5'].detach()\n",
    "        vgg_pool4 = vgg_features['pool4'].detach()\n",
    "        vgg_pool3 = vgg_features['pool3'].detach()\n",
    "\n",
    "        h = self.conv1(vgg_pool5)\n",
    "        h = self.relu(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = self.relu(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        h2 = 0.01 * vgg_pool4\n",
    "        h3 = 0.0001 * vgg_pool3 \n",
    "\n",
    "        h1 = self.classifier1(h)\n",
    "        h2 = self.classifier2(h2)\n",
    "        h3 = self.classifier3(h3)\n",
    "\n",
    "        h1 = self.trans1(h1)\n",
    "        h2 = transforms.functional.crop(h2, top=5, left=5, height=h1.shape[-2], width=h1.shape[-1])\n",
    "        h1 = h1 + h2 \n",
    "\n",
    "        h1 = self.trans2(h1)\n",
    "        h3 = transforms.functional.crop(h3, top=9, left=9, height=h1.shape[-2], width=h1.shape[-1])\n",
    "        h1 = h1 + h3 \n",
    "\n",
    "        h1 = self.trans3(h1)\n",
    "        out = transforms.functional.crop(h1, top=31, left=31, height=x.shape[-2], width=x.shape[-1])       \n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
