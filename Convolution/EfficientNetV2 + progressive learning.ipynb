{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import StochasticDepth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_dim, reduction_ratio=16, use_residual=False) -> None:\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim//reduction_ratio, kernel_size=1, stride=1),\n",
    "            nn.SiLU(), # nn.ReLU()\n",
    "            nn.Conv2d(in_channels=in_dim//reduction_ratio, out_channels=in_dim, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        se_out = self.squeeze(x)\n",
    "        se_out = self.excitation(se_out)\n",
    "        se_out = se_out * x \n",
    "\n",
    "        if self.use_residual:\n",
    "            se_out += x\n",
    "        \n",
    "        return se_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, expasion_ratio=4, squeeze_ratio=4, kernel_size=3, stride=1) -> None:\n",
    "        super(MBConv, self).__init__()\n",
    "        self.use_residual = in_dim == out_dim and stride == 1\n",
    "        hidden_dim = int ( in_dim * expasion_ratio)\n",
    "        padding = kernel_size // 2  # if kernel size 3 -> padding 1, kerenl size 5 -> padding 2\n",
    "\n",
    "        self.expasion = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=hidden_dim, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.dwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=kernel_size, stride=stride, padding=padding, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.se = SqueezeExcitation(in_dim,hidden_dim, reduction_ratio=squeeze_ratio)\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_dim, out_channels=out_dim, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.expasion(x)\n",
    "        h = self.dwise(h)\n",
    "        h = self.se(h)\n",
    "        h = self.projection(h)\n",
    "\n",
    "        if self.use_residual:\n",
    "            h = h + x \n",
    "\n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedMBConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, expasion_ratio=4, kernel_size=3, stride=1) -> None:\n",
    "        super(MBConv, self).__init__()\n",
    "        self.use_residual = in_dim == out_dim and stride == 1\n",
    "        hidden_dim = int ( in_dim * expasion_ratio)\n",
    "        padding = kernel_size // 2  # if kernel size 3 -> padding 1, kerenl size 5 -> padding 2\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=hidden_dim, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.se = SqueezeExcitation(hidden_dim,hidden_dim, reduction_ratio=16)\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_dim, out_channels=out_dim, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.conv(x)\n",
    "        h = self.se(h)\n",
    "        h = self.projection(h)\n",
    "\n",
    "        if self.use_residual:\n",
    "            h = h + x \n",
    "\n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientNetV2_S model \n",
    "class efficientNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000) -> None:\n",
    "        super(efficientNetV2, self).__init__()\n",
    "\n",
    "        hidden_dim = [24, 24, 48, 64, 128, 160, 256, 1280]\n",
    "\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=hidden_dim[0], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # c 24 -> 24\n",
    "        self.conv1 = nn.Sequential(\n",
    "            *([FusedMBConv(in_dim=hidden_dim[0], out_dim=hidden_dim[1], expasion_ratio=1, stride=1) for _ in range(1)]\n",
    "              + [FusedMBConv(in_dim=hidden_dim[1], out_dim=hidden_dim[1], expasion_ratio=1, stride=1)])\n",
    "        )\n",
    "\n",
    "        # c 24 -> 48\n",
    "        self.conv2 = nn.Sequential(\n",
    "            *([FusedMBConv(in_dim=hidden_dim[1], out_dim=hidden_dim[2], expasion_ratio=4, kernel_size=3, stride=2)]\n",
    "            + [FusedMBConv(in_dim=hidden_dim[2], out_dim=hidden_dim[2], expasion_ratio=4, kernel_size=3, stride=1) for _ in range(3)])\n",
    "        )\n",
    "\n",
    "        # c 48 -> 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            *([FusedMBConv(in_dim=hidden_dim[2], out_dim=hidden_dim[3], expasion_ratio=4, kernel_size=3, stride=2)]\n",
    "            + [FusedMBConv(in_dim=hidden_dim[3], out_dim=hidden_dim[3], expasion_ratio=4, kernel_size=3, stride=1) for _ in range(3)])\n",
    "        )\n",
    "\n",
    "        # c 64 -> 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            *([MBConv(in_dim=hidden_dim[3], out_dim=hidden_dim[4], expasion_ratio=4, squeeze_ratio=4, kernel_size=3, stride=2)]\n",
    "            + [MBConv(in_dim=hidden_dim[4], out_dim=hidden_dim[4], expasion_ratio=4, squeeze_ratio=4, kernel_size=3, stride=1) for _ in range(5)])\n",
    "        )\n",
    "\n",
    "        # c 128 -> 160\n",
    "        self.conv5 = nn.Sequential(\n",
    "            *([MBConv(in_dim=hidden_dim[4], out_dim=hidden_dim[5], expasion_ratio=6, squeeze_ratio=4, kernel_size=3, stride=1)]\n",
    "            + [MBConv(in_dim=hidden_dim[5], out_dim=hidden_dim[5], expasion_ratio=6, squeeze_ratio=4, kernel_size=3, stride=1) for _ in range(8)])\n",
    "        )\n",
    "\n",
    "        # c 160 -> 256\n",
    "        self.conv6 = nn.Sequential(\n",
    "            *([MBConv(in_dim=hidden_dim[5], out_dim=hidden_dim[6], expasion_ratio=6, squeeze_ratio=4, kernel_size=3, stride=2)]\n",
    "            + [MBConv(in_dim=hidden_dim[6], out_dim=hidden_dim[6], expasion_ratio=6, squeeze_ratio=4, kernel_size=3, stride=1) for _ in range(14)])\n",
    "        )\n",
    "\n",
    "        # c 256 -> 1280\n",
    "        self.last_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_dim[6], out_channels=hidden_dim[7], kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Conv2d(in_channels=hidden_dim[7], out_channels=num_classes, kernel_size=1, stride=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.init_conv(x)\n",
    "\n",
    "        h = self.conv1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.conv4(h)\n",
    "        h = self.conv5(h)\n",
    "        h = self.conv6(h)\n",
    "\n",
    "        h = self.last_conv(h)\n",
    "\n",
    "        p = self.pooling(h)\n",
    "\n",
    "        out = self.fc(p)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progressive learning example\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transformations to be applied to the input images\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # resize the input images to 256x256\n",
    "    transforms.RandomCrop((224, 224)), # crop the input images to 224x224 randomly\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # resize the input images to 256x256\n",
    "    transforms.CenterCrop((224, 224)), # crop the input images to 224x224 at the center\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = datasets.ImageFolder(\"train/\", transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(\"val/\", transform=transform_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.2) # initial value of dropout probability\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Instantiate model\n",
    "model = MyModel(input_dim=224*224*3, hidden_dim=100, output_dim=2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(10):\n",
    "    # Increase image size\n",
    "    if epoch == 3:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((512, 512)), # resize the input images to 512x512\n",
    "            transforms.RandomCrop((448, 448)), # crop the input images to 448x448 randomly\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        train_dataset = datasets.ImageFolder(\"train/\", transform=transform_train)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Train for one epoch\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.view(inputs.size(0), -1) # flatten the input images\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.view(inputs.size(0), -1) # flatten the input images\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels)\n",
    "            val_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        val_loss /= len(val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc79a4e7eea126714ace4d17b6ce673f58109b4923be81845501021bf3643639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
