{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation**    \n",
    "*Huimin Huang, Lanfen Lin, Ruofeng Tong, Hongjie Hu, Qiaowei Zhang, Yutaro Iwamoto, Xianhua Han, Yen-Wei Chen, Jian Wu*   \n",
    "[[paper](https://arxiv.org/abs/2004.08790)]   \n",
    "ICASSP(IEEE) 2020   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim,\n",
    "                    conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.ReLU) -> None:\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        if norm_type is None:\n",
    "            self.conv = nn.Sequential(\n",
    "                    conv_type(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "                    act_type()\n",
    "                )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                    conv_type(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
    "                    norm_type(out_dim),\n",
    "                    act_type()\n",
    "                )\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.conv(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=None, num_conv=2,\n",
    "                    conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.ReLU) -> None:\n",
    "        assert num_conv > 0\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = out_dim\n",
    "\n",
    "        if num_conv == 1:\n",
    "            self.blocks = ConvLayer(in_dim, out_dim,\n",
    "                                    conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.LeakyReLU)\n",
    "        else:\n",
    "            self.blocks = nn.Sequential(\n",
    "                    *(\n",
    "                        [ConvLayer(in_dim, hidden_dim,\n",
    "                                    conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.LeakyReLU)]\n",
    "                        + [ConvLayer(hidden_dim, hidden_dim, \n",
    "                                     conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.LeakyReLU) for _ in range(num_conv - 2)]\n",
    "                        + [ConvLayer(hidden_dim, out_dim,\n",
    "                                    conv_type=nn.Conv2d, norm_type=nn.BatchNorm2d, act_type=nn.LeakyReLU)]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.blocks(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsamplingLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, is_deconv=True, mode='bilinear') -> None:\n",
    "        super(UpsamplingLayer, self).__init__()\n",
    "\n",
    "        if is_deconv:\n",
    "            self.upsampler = nn.ConvTranspose2d(in_dim, out_dim, kernel_size=2, stride=2, padding=0)\n",
    "        else:\n",
    "            self.upsampler = nn.Upsample(scale_factor=2, mode=mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsampler(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dim = 32\n",
    "\n",
    "        self.conv1 = ConvBlock(1, self.dim, num_conv=2)\n",
    "        self.conv2 = ConvBlock(self.dim, self.dim*2, num_conv=2)\n",
    "        self.conv3 = ConvBlock(self.dim*2, self.dim*4, num_conv=2)\n",
    "        self.conv4 = ConvBlock(self.dim*4, self.dim*8, num_conv=2)\n",
    "        self.conv5 = ConvBlock(self.dim*8, self.dim*16,num_conv=2)\n",
    "\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        conv1_out = self.conv1(inputs)\n",
    "        h1 = self.pool(conv1_out)\n",
    "\n",
    "        conv2_out = self.conv2(h1)\n",
    "        h2 = self.pool(conv2_out)\n",
    "\n",
    "        conv3_out = self.conv3(h2)\n",
    "        h3 = self.pool(conv3_out)\n",
    "\n",
    "        conv4_out = self.conv4(h3)\n",
    "        h4 = self.pool(conv4_out)\n",
    "\n",
    "        conv5_out = self.conv5(h4)\n",
    "        h5 = self.pool(conv5_out)\n",
    "\n",
    "        stage_outputs = [conv1_out, conv2_out, conv3_out, conv4_out]\n",
    "\n",
    "        return h5, stage_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_backbone(nn.modules):\n",
    "    def __init__(self) -> None:\n",
    "        super(VGG16_backbone, self).__init__()\n",
    "        import torchvision.models as models\n",
    "\n",
    "        self.CNN_encoder = models.vgg16(weights=models.VGG16_Weights.DEFAULT).features # weights=VGG16_Weights.IMAGENET1K_V1\n",
    "\n",
    "    def vgg_layer_forward(self, x, indices):\n",
    "        output = x\n",
    "        start_idx, end_idx = indices\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            if idx == (end_idx-1):\n",
    "                pooling = self.CNN_encoder[idx](output)\n",
    "            else:\n",
    "                output = self.CNN_encoder[idx](output)\n",
    "        return pooling, output\n",
    "\n",
    "    def vgg_forward(self, x):\n",
    "        out = {}\n",
    "        depth = 5\n",
    "        layer_indices = [0, 5, 10, 15, 20, 24] # \n",
    "        for layer_num in range(len(depth)-1):\n",
    "            pooling, output = self.vgg_layer_forward(x, layer_indices[layer_num:layer_num+2])\n",
    "            out[f'pool{layer_num+1}'] = pooling\n",
    "            out[f'conv{layer_num+1}'] = output\n",
    "        return out\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        vgg_enc_out = self.CNN_encoder(inputs)\n",
    "\n",
    "        vgg_conv1 = vgg_enc_out['conv1'].detach()\n",
    "        vgg_conv2 = vgg_enc_out['conv2'].detach()\n",
    "        vgg_conv3 = vgg_enc_out['conv3'].detach()\n",
    "        vgg_conv4 = vgg_enc_out['conv4'].detach()\n",
    "        vgg_conv5 = vgg_enc_out['conv5'].detach()\n",
    "\n",
    "        stage_outputs = [vgg_conv4, vgg_conv3, vgg_conv2, vgg_conv1]\n",
    "\n",
    "        return vgg_conv5, stage_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet101_backbone(nn.modules):\n",
    "    def __init__(self) -> None:\n",
    "        super(ResNet101_backbone, self).__init__()\n",
    "        import torchvision.models as models\n",
    "\n",
    "        self.ResNet101 = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "        self.conv1     = nn.Sequential(\n",
    "                            self.ResNet101.conv1, # (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "                            self.ResNet101.bn1,   # (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "                            self.ResNet101.relu   # (relu): ReLU(inplace=True)\n",
    "                        )\n",
    "        self.init_pool = self.ResNet101.maxpool # (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "\n",
    "        self.conv2     = self.ResNet101.layer1\n",
    "        self.conv3     = self.ResNet101.layer2\n",
    "        self.conv4     = self.ResNet101.layer3\n",
    "        self.conv5     = self.ResNet101.layer4\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        h1 = self.conv1(inputs)\n",
    "        p1 = self.init_pool(h1)\n",
    "\n",
    "        h2 = self.conv2(p1)\n",
    "        h3 = self.conv3(h2)\n",
    "        h4 = self.conv4(h3)\n",
    "        h5 = self.conv5(h4)\n",
    "\n",
    "        stage_outputs = [h4, h3, h2, h1]\n",
    "\n",
    "        return h5, stage_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullScale_SkipConnection(nn.Module):\n",
    "    def __init__(self, enc_init_dim=64, skip_hidden_dim=64, decoding_dim=320, dec_depth=4, level=0) -> None:\n",
    "        assert level > 0\n",
    "        super(FullScale_SkipConnection, self).__init__()\n",
    "\n",
    "        \n",
    "        self.feature_aggregator = nn.ModuleList([])\n",
    "\n",
    "\n",
    "        # X5_en (dim=enc_init_dim* # pooling(=dec_depth))\n",
    "        self.feature_aggregator.append(\n",
    "            nn.Sequential(\n",
    "                UpsamplingLayer(-1, -1, is_deconv=False, mode='bilinear'),\n",
    "                ConvLayer(enc_init_dim*2**dec_depth, skip_hidden_dim, norm_type=None)\n",
    "            )\n",
    "        )\n",
    "        for L in range(dec_depth, 0, -1): # l, l-1, ... , 1\n",
    "            \n",
    "            if L > level: # lower level (needed to up scale)\n",
    "                self.feature_aggregator.append(\n",
    "                    nn.Sequential(\n",
    "                        UpsamplingLayer(-1, -1, is_deconv=False, mode='bilinear'),\n",
    "                        ConvLayer(decoding_dim, skip_hidden_dim, norm_type=None)\n",
    "                    )\n",
    "                )\n",
    "            elif L == level: # same level\n",
    "                self.feature_aggregator.append(\n",
    "                    ConvLayer(enc_init_dim*2**(L-1), skip_hidden_dim, norm_type=None) # norm_type=None -> weight-ReLU\n",
    "                )\n",
    "            elif L < level: # upper level (needed to down sampling)\n",
    "                self.feature_aggregator.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.MaxPool2d(kernel_size=dec_depth//L, stride=dec_depth//L), # if level=1 -> Maxpooling(4,4)\n",
    "                        ConvLayer(enc_init_dim*2**(L-1), skip_hidden_dim, norm_type=None)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def forward(self, stage_outputs):\n",
    "\n",
    "        \n",
    "        skip_out1 = self.feature_aggregator[0](stage_outputs[0]) # x5_de\n",
    "        skip_out2 = self.feature_aggregator[1](stage_outputs[1])\n",
    "        skip_out3 = self.feature_aggregator[2](stage_outputs[2])\n",
    "        skip_out4 = self.feature_aggregator[3](stage_outputs[3])\n",
    "        skip_out5 = self.feature_aggregator[4](stage_outputs[4]) # x1_en\n",
    "\n",
    "        skip_out = [skip_out1, skip_out2, skip_out3, skip_out4, skip_out5]\n",
    "        skip_out = torch.concat(skip_out, dim=1)\n",
    "\n",
    "        return skip_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoding_dim = 320\n",
    "\n",
    "        self.skip1 = FullScale_SkipConnection(dec_depth=4, level=4)\n",
    "        self.conv1 = ConvBlock(self.decoding_dim, self.decoding_dim, num_conv=1)\n",
    "\n",
    "        self.skip2 = FullScale_SkipConnection(dec_depth=4, level=3)\n",
    "        self.conv2 = ConvBlock(self.decoding_dim, self.decoding_dim, num_conv=1)\n",
    "\n",
    "        self.skip3 = FullScale_SkipConnection(dec_depth=4, level=2)\n",
    "        self.conv3 = ConvBlock(self.decoding_dim, self.decoding_dim, num_conv=1)\n",
    "\n",
    "        self.skip4 = FullScale_SkipConnection(dec_depth=4, level=1)\n",
    "        self.conv4 = ConvBlock(self.decoding_dim, self.decoding_dim, num_conv=1)\n",
    "\n",
    "        # deep supervision 구현 안 함    \n",
    "        self.dsv1  = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=16, mode='bilinear'),\n",
    "                        nn.Conv2d(1024, 2, kernel_size=1, stride=1, padding=0)\n",
    "                    )\n",
    "        self.dsv2  = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=8, mode='bilinear'),\n",
    "                        nn.Conv2d(self.decoding_dim, 2, kernel_size=1, stride=1, padding=0)\n",
    "                    )\n",
    "        self.dsv3  = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=4, mode='bilinear'),\n",
    "                        nn.Conv2d(self.decoding_dim, 2, kernel_size=1, stride=1, padding=0)\n",
    "                    )\n",
    "        self.dsv4  = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                        nn.Conv2d(self.decoding_dim, 2, kernel_size=1, stride=1, padding=0)\n",
    "                    )\n",
    "        self.dsv5  = nn.Conv2d(self.decoding_dim, 2, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        \n",
    "    def forward(self, enc_out, stage_outputs, organ_flag=True):\n",
    "\n",
    "        stage_outputs = [enc_out] + stage_outputs\n",
    "        skip_out = self.skip1(stage_outputs) \n",
    "        x4_de    = self.conv1(skip_out) # x4_de\n",
    "\n",
    "        stage_outputs[1] = x4_de\n",
    "        skip_out = self.skip2(stage_outputs)\n",
    "        x3_de    = self.conv2(skip_out)\n",
    "\n",
    "        stage_outputs[2] = x3_de\n",
    "        skip_out = self.skip3(stage_outputs)\n",
    "        x2_de    = self.conv3(skip_out)\n",
    "\n",
    "        stage_outputs[3] = x2_de\n",
    "        skip_out = self.skip4(x2_de, stage_outputs)\n",
    "        x1_de    = self.conv4(skip_out)\n",
    "        \n",
    "        x4_de    *= organ_flag\n",
    "        x3_de    *= organ_flag\n",
    "        x2_de    *= organ_flag\n",
    "        x1_de    *= organ_flag\n",
    "\n",
    "        dsv1_out = self.dsv1(enc_out)\n",
    "        dsv2_out = self.dsv2(x4_de)\n",
    "        dsv3_out = self.dsv3(x3_de)\n",
    "        dsv4_out = self.dsv4(x2_de)\n",
    "        out = self.dsv5(x1_de)\n",
    "\n",
    "        return out, dsv4_out, dsv3_out, dsv2_out, dsv1_out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3p(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(UNet3p, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        # self.encoder = VGG16_backbone()\n",
    "        # self.encoder = ResNet101_backbone()\n",
    "        self.decoder = Decoder()\n",
    "        self.classification_guide = nn.Sequential(\n",
    "                                        nn.Dropout2d(),\n",
    "                                        nn.Conv2d(1024, 2, kernel_size=1, stride=1, padding=0),\n",
    "                                        nn.AdaptiveAvgPool2d(1),\n",
    "                                        nn.Sigmoid()\n",
    "                                    )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        enc_out, stage_outputs = self.encoder(inputs)\n",
    "        organ_flag = torch.argmax(self.classification_guide(enc_out), dim=1)\n",
    "        out, dsv4_out, dsv3_out, dsv2_out, dsv1_out = self.Decoder(enc_out, stage_outputs, organ_flag)\n",
    "\n",
    "        return out, dsv4_out, dsv3_out, dsv2_out, dsv1_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8034245bc4d3529f9d9ffcd1c0ba194efca112f5dbacb6a250b6873c232e499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
